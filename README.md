# snctl-cpp

The CLI tool to manage clusters on StreamNative Cloud.

## How to install

### (Recommended) Use pre-built binaries

Currently the release only supports macOS 14 or later with arm64 architecture.

Take v0.1.0 for example:

```bash
export VERSION=0.1.0
curl -O -L https://github.com/BewareMyPower/snctl-cpp/releases/download/v$VERSION/snctl-cpp-macos-14-arm64.zip
unzip -q snctl-cpp-macos-14-arm64.zip
./install.sh
```

The binary and configuration file will be installed under `~/.snctl-cpp`, so you have to add it to your `PATH`:

```bash
export PATH=$HOME/.snctl-cpp:$PATH
```

Now, you can run `snctl-cpp -h` to see the help message.

### Build from source

You must have a C++ compiler that supports C++17.

```bash
git submodule update --init --recursive
cmake -B build
cmake --build build
cp build/snctl-cpp .
```

You can run `./install.sh` to override the existing installation in `~/.snctl-cpp` directory, but you can also just run `./snctl-cpp` directly without installing it. The `sncloud.ini` file in the current working directory has higher priority than the one in `~/.snctl-cpp` directory.

## How to manage topics in the cluster that enables Kafka protocol

**Please make sure the `sncloud.ini` file is in the current working directory or `~/.snctl-cpp` directory if you don't specify the `--config` option.**

You only need to fill the following fields in `sncloud.ini`:
- `bootstrap.servers`: the URL of the Kafka service, e.g. `pc-xxx:9093` on StreamNative cloud.
- (optional) `token`: the token generated by the API key. It's allowed to be empty for quickly testing against a local Kafka cluster without any authentication.

Options:
- Add the `--config <config-file>` option to specify a different path of the INI config file.
- Add a `--client-id` option to specify the client id of the underlying Kafka client. In Ursa, the client id carries the zone information, see [here](https://docs.streamnative.io/docs/config-kafka-client#eliminate-cross-az-networking-traffic).

### Create a topic

```bash
$ snctl-cpp create tp0
Created topic "tp0" with 1 partition
$ snctl-cpp create tp1 -p 5
Created topic "tp1" with 5 partitions
```

### Delete a topic

```bash
$ snctl-cpp delete tp
Failed to delete topic "tp": Broker: Unknown topic or partition
$ snctl-cpp delete tp0
Deleted topic "tp0"
```

### Describe a topic

Query the owner brokers for all partitions:

```bash
$ snctl-cpp describe <topic>
Partition[0] leader: {"id": 816909419, url: "pb0-<xxx>:9093"}"
Partition[1] leader: {"id": 101337027, url: "pb4-<xxx>:9093"}"
...
Partition[15] leader: {"id": 644587507, url: "pb2-<xxx>:9093"}"
```

Query the owner brokers for all partitions in a specific zone (`use1-az1` in this case):

```bash
$ snctl-cpp --client-id zone_id=use1-az1 describe <topic>
Partition[0] leader: {"id": 1868363245, url: "pb5-<xxx>:9093"}
Partition[1] leader: {"id": 1868363245, url: "pb5-<xxx>:9093"}
...
Partition[15] leader: {"id": 644587507, url: "pb2-<xxx>:9093"}
```

As you can see, when a client specifies `use1-az1` as its zone, only brokers in the same zone (`pb2` and `pb5`) will serve the requests from that client.

### List topics

List all topics and print the number of partitions for each topic:

```bash
$ snctl-cpp list
topic count: 2
[0] "my-topic-2" with 1 partition
[1] "my-topic-1" with 10 partitions
```

## Logging

By default, rdkafka will generate logs to the standard output. `snctl-cpp` can redirect the logs to a file. For example, with the following configs in `sncloud.ini`:

```toml
[log]
enabled = true
path = /tmp/rdkafka.log
```

The logs will be appended to the `/tmp/rdkafka.log` file. If you don't want to generate any log from rdkafka, you can configure `enabled` with `false`.
